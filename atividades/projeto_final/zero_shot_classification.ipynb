{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91713c45",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be8bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: pandas==2.3.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: transformers==4.57.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (4.57.1)\n",
      "Requirement already satisfied: tf-keras==2.20.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.20.1)\n",
      "Requirement already satisfied: kagglehub in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.3.13)\n",
      "Requirement already satisfied: scikit-learn==1.7.2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
      "Requirement already satisfied: hf_xet==1.2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tf-keras==2.20.1->-r requirements.txt (line 3)) (2.20.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from scikit-learn==1.7.2->-r requirements.txt (line 5)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from scikit-learn==1.7.2->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from scikit-learn==1.7.2->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1->-r requirements.txt (line 2)) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (6.33.1)\n",
      "Requirement already satisfied: setuptools in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.1.3)\n",
      "Requirement already satisfied: psutil in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from accelerate>=0.26.0->-r requirements.txt (line 7)) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from accelerate>=0.26.0->-r requirements.txt (line 7)) (2.8.0+cu129)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.57.1->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.1.2)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu129\n",
      "Requirement already satisfied: torch in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r other-requirements.txt (line 2)) (2.8.0+cu129)\n",
      "Requirement already satisfied: torchvision in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r other-requirements.txt (line 3)) (0.23.0+cu129)\n",
      "Requirement already satisfied: torchaudio in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r other-requirements.txt (line 4)) (2.8.0+cu129)\n",
      "Requirement already satisfied: filelock in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torchvision->-r other-requirements.txt (line 3)) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torchvision->-r other-requirements.txt (line 3)) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r other-requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from jinja2->torch->-r other-requirements.txt (line 2)) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt\n",
    "!pip install -r other-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub \n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b78dc",
   "metadata": {},
   "source": [
    "### ENV VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT_OF_REVIEWS_TO_CLASSIFY = 300\n",
    "NUM_TRAIN_EPOCHS = 3 # 2 ou 3 épocas\n",
    "WARMUP_STEPS = 500 # Passos de aquecimento para o otimizador\n",
    "WEIGHT_DECAY = 0.01 # Decaimento de peso para o otimizador\n",
    "TRAIN_SAMPLE_SIZE = 4000 # Tamanho da amostra de treino\n",
    "MODEL_CHECKPOINT = \"distilbert-base-uncased\" # modelo leve para o fine-tuning - DistilBERT - rápido de treinar e tem ótima performance.\n",
    "KAGGLE_DATASET = \"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\" # Dataset do Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abebd431",
   "metadata": {},
   "source": [
    "### DATASET - IMDB MOVIE REVIEWS TO CLASSIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f4b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\wks\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\rafas\\.cache\\kagglehub\\datasets\\lakshmi25npathi\\imdb-dataset-of-50k-movie-reviews\\versions\\1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kind of drawn in by the erotic scenes, only to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Some films just simply should not be remade. T...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This movie made it into one of my top 10 most ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I remember this film,it was the first film i h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>An awful film! It must have been up against so...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5   Probably my all-time favorite movie, a story o...  positive\n",
       "6   I sure would like to see a resurrection of a u...  positive\n",
       "7   This show was an amazing, fresh & innovative i...  negative\n",
       "8   Encouraged by the positive comments about this...  negative\n",
       "9   If you like original gut wrenching laughter yo...  positive\n",
       "10  Phil the Alien is one of those quirky films wh...  negative\n",
       "11  I saw this movie when I was about 12 when it c...  negative\n",
       "12  So im not a big fan of Boll's work but then ag...  negative\n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative\n",
       "14  This a fantastic movie of three prisoners who ...  positive\n",
       "15  Kind of drawn in by the erotic scenes, only to...  negative\n",
       "16  Some films just simply should not be remade. T...  positive\n",
       "17  This movie made it into one of my top 10 most ...  negative\n",
       "18  I remember this film,it was the first film i h...  positive\n",
       "19  An awful film! It must have been up against so...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset IMDB reviews\n",
    "path = kagglehub.dataset_download(KAGGLE_DATASET)\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "df = pd.read_csv(path + \"/IMDB Dataset.csv\")    \n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611110a",
   "metadata": {},
   "source": [
    "### SET GPU CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5287fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 14 01:39:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 577.00                 Driver Version: 577.00         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P3             14W /   60W |       0MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "GPU disponível? True\n",
      "Nome da GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Dispositivo selecionado: cuda:0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "print(f\"GPU disponível? {torch.cuda.is_available()}\")\n",
    "print(f\"Nome da GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Nenhuma'}\")\n",
    "\n",
    "# 1. Verifica se a GPU (CUDA) está disponível\n",
    "#    Se estiver, usa \"cuda:0\" (a primeira GPU)\n",
    "#    Se não, usa \"cpu\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Dispositivo selecionado: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\dev\\python\\wks\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                      device=device)  # Use GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a058538",
   "metadata": {},
   "source": [
    "#### USE BART LARGE MNLI MODEL TO CLASSIFY MOVIE REVIEWS IN POSITIVE/NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e04df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1 classification:\n",
      "positive with score 0.5315369367599487\n",
      "Review 2 classification:\n",
      "positive with score 0.9874507784843445\n",
      "Review 3 classification:\n",
      "positive with score 0.9743620753288269\n",
      "Review 4 classification:\n",
      "negative with score 0.9753220081329346\n",
      "Review 5 classification:\n",
      "positive with score 0.8379409313201904\n",
      "Review 6 classification:\n",
      "positive with score 0.9739865660667419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 7 classification:\n",
      "positive with score 0.7787741422653198\n",
      "Review 8 classification:\n",
      "negative with score 0.9267164468765259\n",
      "Review 9 classification:\n",
      "negative with score 0.8084461092948914\n",
      "Review 10 classification:\n",
      "positive with score 0.9694986343383789\n",
      "Review 11 classification:\n",
      "negative with score 0.8875367045402527\n",
      "Review 12 classification:\n",
      "negative with score 0.5397162437438965\n",
      "Review 13 classification:\n",
      "negative with score 0.8973174691200256\n",
      "Review 14 classification:\n",
      "negative with score 0.9752565622329712\n",
      "Review 15 classification:\n",
      "positive with score 0.9951791167259216\n",
      "Review 16 classification:\n",
      "negative with score 0.9860522150993347\n",
      "Review 17 classification:\n",
      "negative with score 0.8709798455238342\n",
      "Review 18 classification:\n",
      "negative with score 0.9806430339813232\n",
      "Review 19 classification:\n",
      "positive with score 0.5455807447433472\n",
      "Review 20 classification:\n",
      "negative with score 0.9686130881309509\n",
      "Review 21 classification:\n",
      "positive with score 0.8618015050888062\n",
      "Review 22 classification:\n",
      "negative with score 0.9835595488548279\n",
      "Review 23 classification:\n",
      "positive with score 0.9763799905776978\n",
      "Review 24 classification:\n",
      "negative with score 0.7895453572273254\n",
      "Review 25 classification:\n",
      "negative with score 0.9744898080825806\n",
      "Review 26 classification:\n",
      "negative with score 0.7800610065460205\n",
      "Review 27 classification:\n",
      "positive with score 0.7609129548072815\n",
      "Review 28 classification:\n",
      "negative with score 0.9933624267578125\n",
      "Review 29 classification:\n",
      "negative with score 0.9524261951446533\n",
      "Review 30 classification:\n",
      "negative with score 0.6398018002510071\n",
      "Review 31 classification:\n",
      "negative with score 0.8711932301521301\n",
      "Review 32 classification:\n",
      "negative with score 0.6838828325271606\n",
      "Review 33 classification:\n",
      "negative with score 0.9769946336746216\n",
      "Review 34 classification:\n",
      "positive with score 0.654692530632019\n",
      "Review 35 classification:\n",
      "negative with score 0.8967625498771667\n",
      "Review 36 classification:\n",
      "negative with score 0.968262791633606\n",
      "Review 37 classification:\n",
      "negative with score 0.9708064198493958\n",
      "Review 38 classification:\n",
      "negative with score 0.9838340282440186\n",
      "Review 39 classification:\n",
      "negative with score 0.5115513205528259\n",
      "Review 40 classification:\n",
      "negative with score 0.8882899880409241\n",
      "Review 41 classification:\n",
      "negative with score 0.9466449618339539\n",
      "Review 42 classification:\n",
      "positive with score 0.9922139048576355\n",
      "Review 43 classification:\n",
      "negative with score 0.9135808944702148\n",
      "Review 44 classification:\n",
      "negative with score 0.9038060307502747\n",
      "Review 45 classification:\n",
      "negative with score 0.7097226977348328\n",
      "Review 46 classification:\n",
      "positive with score 0.9429440498352051\n",
      "Review 47 classification:\n",
      "negative with score 0.7758607864379883\n",
      "Review 48 classification:\n",
      "negative with score 0.979798436164856\n",
      "Review 49 classification:\n",
      "negative with score 0.6387069821357727\n",
      "Review 50 classification:\n",
      "negative with score 0.7223299145698547\n",
      "Review 51 classification:\n",
      "positive with score 0.88062584400177\n",
      "Review 52 classification:\n",
      "negative with score 0.9105003476142883\n",
      "Review 53 classification:\n",
      "positive with score 0.9642540216445923\n",
      "Review 54 classification:\n",
      "positive with score 0.9709616899490356\n",
      "Review 55 classification:\n",
      "negative with score 0.9041277766227722\n",
      "Review 56 classification:\n",
      "negative with score 0.9686857461929321\n",
      "Review 57 classification:\n",
      "positive with score 0.6155502200126648\n",
      "Review 58 classification:\n",
      "negative with score 0.9842618703842163\n",
      "Review 59 classification:\n",
      "positive with score 0.8144046664237976\n",
      "Review 60 classification:\n",
      "positive with score 0.8548496961593628\n",
      "Review 61 classification:\n",
      "negative with score 0.9138836860656738\n",
      "Review 62 classification:\n",
      "negative with score 0.9549124836921692\n",
      "Review 63 classification:\n",
      "positive with score 0.9695194959640503\n",
      "Review 64 classification:\n",
      "negative with score 0.9865286350250244\n",
      "Review 65 classification:\n",
      "negative with score 0.8571093678474426\n",
      "Review 66 classification:\n",
      "positive with score 0.939877986907959\n",
      "Review 67 classification:\n",
      "negative with score 0.5627765655517578\n",
      "Review 68 classification:\n",
      "negative with score 0.7999482154846191\n",
      "Review 69 classification:\n",
      "negative with score 0.9900488257408142\n",
      "Review 70 classification:\n",
      "negative with score 0.5779730677604675\n",
      "Review 71 classification:\n",
      "negative with score 0.6432793736457825\n",
      "Review 72 classification:\n",
      "positive with score 0.5136587023735046\n",
      "Review 73 classification:\n",
      "positive with score 0.7492619752883911\n",
      "Review 74 classification:\n",
      "positive with score 0.9424377679824829\n",
      "Review 75 classification:\n",
      "negative with score 0.8212389349937439\n",
      "Review 76 classification:\n",
      "positive with score 0.9063795804977417\n",
      "Review 77 classification:\n",
      "negative with score 0.6848583817481995\n",
      "Review 78 classification:\n",
      "negative with score 0.979216992855072\n",
      "Review 79 classification:\n",
      "negative with score 0.9312541484832764\n",
      "Review 80 classification:\n",
      "positive with score 0.9377666115760803\n",
      "Review 81 classification:\n",
      "positive with score 0.7717342376708984\n",
      "Review 82 classification:\n",
      "negative with score 0.9505108594894409\n",
      "Review 83 classification:\n",
      "negative with score 0.9464884400367737\n",
      "Review 84 classification:\n",
      "negative with score 0.9381583333015442\n",
      "Review 85 classification:\n",
      "negative with score 0.9920385479927063\n",
      "Review 86 classification:\n",
      "negative with score 0.959705114364624\n",
      "Review 87 classification:\n",
      "negative with score 0.9566376805305481\n",
      "Review 88 classification:\n",
      "negative with score 0.9103749990463257\n",
      "Review 89 classification:\n",
      "negative with score 0.9776573777198792\n",
      "Review 90 classification:\n",
      "negative with score 0.9448868036270142\n",
      "Review 91 classification:\n",
      "positive with score 0.968439519405365\n",
      "Review 92 classification:\n",
      "negative with score 0.8419947028160095\n",
      "Review 93 classification:\n",
      "positive with score 0.9849845170974731\n",
      "Review 94 classification:\n",
      "positive with score 0.9219794273376465\n",
      "Review 95 classification:\n",
      "negative with score 0.9696235060691833\n",
      "Review 96 classification:\n",
      "positive with score 0.9377464056015015\n",
      "Review 97 classification:\n",
      "negative with score 0.9385594725608826\n",
      "Review 98 classification:\n",
      "negative with score 0.9758031368255615\n",
      "Review 99 classification:\n",
      "negative with score 0.990547776222229\n",
      "Review 100 classification:\n",
      "positive with score 0.8898029327392578\n",
      "Review 101 classification:\n",
      "positive with score 0.7710204124450684\n",
      "Review 102 classification:\n",
      "negative with score 0.7180094122886658\n",
      "Review 103 classification:\n",
      "positive with score 0.7665901184082031\n",
      "Review 104 classification:\n",
      "positive with score 0.5583751201629639\n",
      "Review 105 classification:\n",
      "negative with score 0.99588942527771\n",
      "Review 106 classification:\n",
      "positive with score 0.867137610912323\n",
      "Review 107 classification:\n",
      "positive with score 0.8758019208908081\n",
      "Review 108 classification:\n",
      "negative with score 0.9287955164909363\n",
      "Review 109 classification:\n",
      "positive with score 0.9118618965148926\n",
      "Review 110 classification:\n",
      "positive with score 0.9811205267906189\n",
      "Review 111 classification:\n",
      "negative with score 0.9060416221618652\n",
      "Review 112 classification:\n",
      "negative with score 0.5524752140045166\n",
      "Review 113 classification:\n",
      "negative with score 0.9159803986549377\n",
      "Review 114 classification:\n",
      "positive with score 0.9301764369010925\n",
      "Review 115 classification:\n",
      "positive with score 0.891693651676178\n",
      "Review 116 classification:\n",
      "positive with score 0.9778469204902649\n",
      "Review 117 classification:\n",
      "negative with score 0.7504372000694275\n",
      "Review 118 classification:\n",
      "negative with score 0.9906818866729736\n",
      "Review 119 classification:\n",
      "negative with score 0.997092068195343\n",
      "Review 120 classification:\n",
      "negative with score 0.7877256870269775\n",
      "Review 121 classification:\n",
      "positive with score 0.7872454524040222\n",
      "Review 122 classification:\n",
      "positive with score 0.9547103643417358\n",
      "Review 123 classification:\n",
      "negative with score 0.9330974817276001\n",
      "Review 124 classification:\n",
      "negative with score 0.9621022939682007\n",
      "Review 125 classification:\n",
      "positive with score 0.6219527125358582\n",
      "Review 126 classification:\n",
      "negative with score 0.7346319556236267\n",
      "Review 127 classification:\n",
      "negative with score 0.9894965887069702\n",
      "Review 128 classification:\n",
      "negative with score 0.9817151427268982\n",
      "Review 129 classification:\n",
      "positive with score 0.9419708847999573\n",
      "Review 130 classification:\n",
      "negative with score 0.5225486755371094\n",
      "Review 131 classification:\n",
      "positive with score 0.9682331085205078\n",
      "Review 132 classification:\n",
      "positive with score 0.8477234244346619\n",
      "Review 133 classification:\n",
      "negative with score 0.96907639503479\n",
      "Review 134 classification:\n",
      "negative with score 0.9925141930580139\n",
      "Review 135 classification:\n",
      "negative with score 0.9863703846931458\n",
      "Review 136 classification:\n",
      "negative with score 0.937062680721283\n",
      "Review 137 classification:\n",
      "positive with score 0.5303652286529541\n",
      "Review 138 classification:\n",
      "negative with score 0.7050961256027222\n",
      "Review 139 classification:\n",
      "positive with score 0.9351311326026917\n",
      "Review 140 classification:\n",
      "negative with score 0.9183641076087952\n",
      "Review 141 classification:\n",
      "positive with score 0.8716161251068115\n",
      "Review 142 classification:\n",
      "negative with score 0.9729540944099426\n",
      "Review 143 classification:\n",
      "negative with score 0.8982897996902466\n",
      "Review 144 classification:\n",
      "positive with score 0.7885333299636841\n",
      "Review 145 classification:\n",
      "negative with score 0.9753483533859253\n",
      "Review 146 classification:\n",
      "positive with score 0.8660062551498413\n",
      "Review 147 classification:\n",
      "positive with score 0.7998676300048828\n",
      "Review 148 classification:\n",
      "positive with score 0.8785467743873596\n",
      "Review 149 classification:\n",
      "negative with score 0.9637159705162048\n",
      "Review 150 classification:\n",
      "negative with score 0.9636299014091492\n",
      "Review 151 classification:\n",
      "positive with score 0.972701370716095\n",
      "Review 152 classification:\n",
      "negative with score 0.9261868596076965\n",
      "Review 153 classification:\n",
      "negative with score 0.9165624380111694\n",
      "Review 154 classification:\n",
      "positive with score 0.9136396646499634\n",
      "Review 155 classification:\n",
      "negative with score 0.9686211347579956\n",
      "Review 156 classification:\n",
      "positive with score 0.7118111848831177\n",
      "Review 157 classification:\n",
      "negative with score 0.6473777294158936\n",
      "Review 158 classification:\n",
      "positive with score 0.9779937267303467\n",
      "Review 159 classification:\n",
      "negative with score 0.8130882978439331\n",
      "Review 160 classification:\n",
      "positive with score 0.7062117457389832\n",
      "Review 161 classification:\n",
      "positive with score 0.9541373252868652\n",
      "Review 162 classification:\n",
      "negative with score 0.8694614171981812\n",
      "Review 163 classification:\n",
      "negative with score 0.9858952164649963\n",
      "Review 164 classification:\n",
      "positive with score 0.6264203190803528\n",
      "Review 165 classification:\n",
      "positive with score 0.896521806716919\n",
      "Review 166 classification:\n",
      "negative with score 0.9875519275665283\n",
      "Review 167 classification:\n",
      "positive with score 0.9470730423927307\n",
      "Review 168 classification:\n",
      "negative with score 0.9468609094619751\n",
      "Review 169 classification:\n",
      "negative with score 0.9156224131584167\n",
      "Review 170 classification:\n",
      "negative with score 0.9030002951622009\n",
      "Review 171 classification:\n",
      "negative with score 0.9675091505050659\n",
      "Review 172 classification:\n",
      "negative with score 0.6548975110054016\n",
      "Review 173 classification:\n",
      "positive with score 0.8948069214820862\n",
      "Review 174 classification:\n",
      "positive with score 0.968346357345581\n",
      "Review 175 classification:\n",
      "negative with score 0.9725276827812195\n",
      "Review 176 classification:\n",
      "negative with score 0.9254629015922546\n",
      "Review 177 classification:\n",
      "positive with score 0.8429919481277466\n",
      "Review 178 classification:\n",
      "negative with score 0.8543403744697571\n",
      "Review 179 classification:\n",
      "positive with score 0.6740792989730835\n",
      "Review 180 classification:\n",
      "negative with score 0.9543314576148987\n",
      "Review 181 classification:\n",
      "positive with score 0.9956834316253662\n",
      "Review 182 classification:\n",
      "negative with score 0.7339786887168884\n",
      "Review 183 classification:\n",
      "negative with score 0.9817541837692261\n",
      "Review 184 classification:\n",
      "negative with score 0.9428430199623108\n",
      "Review 185 classification:\n",
      "negative with score 0.9493365287780762\n",
      "Review 186 classification:\n",
      "negative with score 0.9167117476463318\n",
      "Review 187 classification:\n",
      "positive with score 0.633514404296875\n",
      "Review 188 classification:\n",
      "negative with score 0.8997597098350525\n",
      "Review 189 classification:\n",
      "positive with score 0.7148982882499695\n",
      "Review 190 classification:\n",
      "negative with score 0.9697626233100891\n",
      "Review 191 classification:\n",
      "negative with score 0.6549312472343445\n",
      "Review 192 classification:\n",
      "negative with score 0.5921399593353271\n",
      "Review 193 classification:\n",
      "positive with score 0.8711572289466858\n",
      "Review 194 classification:\n",
      "positive with score 0.9353145360946655\n",
      "Review 195 classification:\n",
      "negative with score 0.9831702709197998\n",
      "Review 196 classification:\n",
      "negative with score 0.9464544057846069\n",
      "Review 197 classification:\n",
      "negative with score 0.95356684923172\n",
      "Review 198 classification:\n",
      "negative with score 0.9630653262138367\n",
      "Review 199 classification:\n",
      "positive with score 0.7413211464881897\n",
      "Review 200 classification:\n",
      "negative with score 0.9523846507072449\n",
      "Review 201 classification:\n",
      "positive with score 0.9854874610900879\n",
      "Review 202 classification:\n",
      "positive with score 0.9664718508720398\n",
      "Review 203 classification:\n",
      "positive with score 0.9356722235679626\n",
      "Review 204 classification:\n",
      "positive with score 0.9860775470733643\n",
      "Review 205 classification:\n",
      "negative with score 0.9786022901535034\n",
      "Review 206 classification:\n",
      "positive with score 0.7470841407775879\n",
      "Review 207 classification:\n",
      "negative with score 0.9770128726959229\n",
      "Review 208 classification:\n",
      "negative with score 0.9556980729103088\n",
      "Review 209 classification:\n",
      "negative with score 0.7602342963218689\n",
      "Review 210 classification:\n",
      "positive with score 0.9912425875663757\n",
      "Review 211 classification:\n",
      "negative with score 0.9801509380340576\n",
      "Review 212 classification:\n",
      "negative with score 0.9898990988731384\n",
      "Review 213 classification:\n",
      "negative with score 0.9499998092651367\n",
      "Review 214 classification:\n",
      "positive with score 0.922360897064209\n",
      "Review 215 classification:\n",
      "negative with score 0.8913975358009338\n",
      "Review 216 classification:\n",
      "positive with score 0.915565550327301\n",
      "Review 217 classification:\n",
      "positive with score 0.8402653336524963\n",
      "Review 218 classification:\n",
      "negative with score 0.9911001920700073\n",
      "Review 219 classification:\n",
      "positive with score 0.952743649482727\n",
      "Review 220 classification:\n",
      "positive with score 0.7356408834457397\n",
      "Review 221 classification:\n",
      "negative with score 0.9567666053771973\n",
      "Review 222 classification:\n",
      "positive with score 0.6264707446098328\n",
      "Review 223 classification:\n",
      "positive with score 0.9623210430145264\n",
      "Review 224 classification:\n",
      "negative with score 0.9668238162994385\n",
      "Review 225 classification:\n",
      "positive with score 0.9706028699874878\n",
      "Review 226 classification:\n",
      "negative with score 0.811926007270813\n",
      "Review 227 classification:\n",
      "positive with score 0.9854366779327393\n",
      "Review 228 classification:\n",
      "positive with score 0.9728647470474243\n",
      "Review 229 classification:\n",
      "positive with score 0.8378109335899353\n",
      "Review 230 classification:\n",
      "negative with score 0.5024967789649963\n",
      "Review 231 classification:\n",
      "negative with score 0.9745340943336487\n",
      "Review 232 classification:\n",
      "positive with score 0.8493054509162903\n",
      "Review 233 classification:\n",
      "positive with score 0.9354747533798218\n",
      "Review 234 classification:\n",
      "positive with score 0.984382688999176\n",
      "Review 235 classification:\n",
      "positive with score 0.8411726951599121\n",
      "Review 236 classification:\n",
      "positive with score 0.9598951935768127\n",
      "Review 237 classification:\n",
      "positive with score 0.9960821866989136\n",
      "Review 238 classification:\n",
      "negative with score 0.9478417634963989\n",
      "Review 239 classification:\n",
      "positive with score 0.5265149474143982\n",
      "Review 240 classification:\n",
      "negative with score 0.9692608118057251\n",
      "Review 241 classification:\n",
      "negative with score 0.9323173761367798\n",
      "Review 242 classification:\n",
      "positive with score 0.9328287839889526\n",
      "Review 243 classification:\n",
      "negative with score 0.9662419557571411\n",
      "Review 244 classification:\n",
      "positive with score 0.7864969968795776\n",
      "Review 245 classification:\n",
      "negative with score 0.777554988861084\n",
      "Review 246 classification:\n",
      "positive with score 0.9841740131378174\n",
      "Review 247 classification:\n",
      "negative with score 0.9097262620925903\n",
      "Review 248 classification:\n",
      "negative with score 0.7863818407058716\n",
      "Review 249 classification:\n",
      "positive with score 0.958777666091919\n",
      "Review 250 classification:\n",
      "negative with score 0.9592649936676025\n",
      "Review 251 classification:\n",
      "negative with score 0.9887470602989197\n",
      "Review 252 classification:\n",
      "negative with score 0.9758188128471375\n",
      "Review 253 classification:\n",
      "positive with score 0.5435454845428467\n",
      "Review 254 classification:\n",
      "negative with score 0.9469601511955261\n",
      "Review 255 classification:\n",
      "positive with score 0.9400620460510254\n",
      "Review 256 classification:\n",
      "negative with score 0.8968517184257507\n",
      "Review 257 classification:\n",
      "negative with score 0.8319737911224365\n",
      "Review 258 classification:\n",
      "negative with score 0.984956681728363\n",
      "Review 259 classification:\n",
      "positive with score 0.9526703357696533\n",
      "Review 260 classification:\n",
      "negative with score 0.7187978029251099\n",
      "Review 261 classification:\n",
      "positive with score 0.8921281099319458\n",
      "Review 262 classification:\n",
      "negative with score 0.983717679977417\n",
      "Review 263 classification:\n",
      "negative with score 0.9354704022407532\n",
      "Review 264 classification:\n",
      "positive with score 0.6300219893455505\n",
      "Review 265 classification:\n",
      "negative with score 0.9897423386573792\n",
      "Review 266 classification:\n",
      "positive with score 0.7617590427398682\n",
      "Review 267 classification:\n",
      "negative with score 0.958538830280304\n",
      "Review 268 classification:\n",
      "negative with score 0.9967035055160522\n",
      "Review 269 classification:\n",
      "negative with score 0.9843102693557739\n",
      "Review 270 classification:\n",
      "positive with score 0.9831261038780212\n",
      "Review 271 classification:\n",
      "negative with score 0.6248809099197388\n",
      "Review 272 classification:\n",
      "positive with score 0.5030534863471985\n",
      "Review 273 classification:\n",
      "negative with score 0.5273182392120361\n",
      "Review 274 classification:\n",
      "positive with score 0.6200319528579712\n",
      "Review 275 classification:\n",
      "negative with score 0.8462034463882446\n",
      "Review 276 classification:\n",
      "positive with score 0.8841032385826111\n",
      "Review 277 classification:\n",
      "negative with score 0.8006092309951782\n",
      "Review 278 classification:\n",
      "positive with score 0.6513875722885132\n",
      "Review 279 classification:\n",
      "negative with score 0.9751793146133423\n",
      "Review 280 classification:\n",
      "negative with score 0.6935847997665405\n",
      "Review 281 classification:\n",
      "positive with score 0.6372582316398621\n",
      "Review 282 classification:\n",
      "negative with score 0.9938397407531738\n",
      "Review 283 classification:\n",
      "negative with score 0.9725120663642883\n",
      "Review 284 classification:\n",
      "negative with score 0.8933386206626892\n",
      "Review 285 classification:\n",
      "positive with score 0.9439030885696411\n",
      "Review 286 classification:\n",
      "negative with score 0.9631600379943848\n",
      "Review 287 classification:\n",
      "negative with score 0.9010180830955505\n",
      "Review 288 classification:\n",
      "positive with score 0.9527976512908936\n",
      "Review 289 classification:\n",
      "positive with score 0.9008016586303711\n",
      "Review 290 classification:\n",
      "positive with score 0.898597240447998\n",
      "Review 291 classification:\n",
      "positive with score 0.6148604154586792\n",
      "Review 292 classification:\n",
      "positive with score 0.9345824718475342\n",
      "Review 293 classification:\n",
      "positive with score 0.5360708236694336\n",
      "Review 294 classification:\n",
      "negative with score 0.9669175744056702\n",
      "Review 295 classification:\n",
      "positive with score 0.9867228269577026\n",
      "Review 296 classification:\n",
      "negative with score 0.968547523021698\n",
      "Review 297 classification:\n",
      "negative with score 0.9697656631469727\n",
      "Review 298 classification:\n",
      "positive with score 0.8887783288955688\n",
      "Review 299 classification:\n",
      "positive with score 0.9484137892723083\n",
      "Review 300 classification:\n",
      "positive with score 0.8788614869117737\n"
     ]
    }
   ],
   "source": [
    "model_classification_results = []\n",
    "\n",
    "for index, row in df.head(AMOUNT_OF_REVIEWS_TO_CLASSIFY).iterrows():\n",
    "    sequence_to_classify = row['review']\n",
    "    candidate_labels = ['positive', 'negative']\n",
    "    result = classifier(sequence_to_classify, candidate_labels)\n",
    "    print(f\"Review {index+1} classification:\")\n",
    "    print(result['labels'][0], \"with score\", result['scores'][0])\n",
    "    \n",
    "    model_classification_results.append({\n",
    "        'review': sequence_to_classify,\n",
    "        'predicted_label': result['labels'][0],\n",
    "        'score': result['scores'][0]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2da16",
   "metadata": {},
   "source": [
    "#### LIST WRONG CLASSIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904f17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total incorrect predictions: 30 - Error percentage: 10.00%\n"
     ]
    }
   ],
   "source": [
    "counter_incorrect = 0\n",
    "for index, row in df.head(AMOUNT_OF_REVIEWS_TO_CLASSIFY).iterrows():\n",
    "    predicted = model_classification_results[index]['predicted_label']\n",
    "    actual_label = row['sentiment']\n",
    "    if predicted != actual_label:\n",
    "        # print(f\"Review {index+1} - Predicted: {predicted}, Actual: {actual_label}\")\n",
    "        counter_incorrect += 1\n",
    "        \n",
    "error_percentage = (counter_incorrect / AMOUNT_OF_REVIEWS_TO_CLASSIFY) * 100\n",
    "print(f\"Total incorrect predictions: {counter_incorrect} - Error percentage: {error_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf404306",
   "metadata": {},
   "source": [
    "#### MÉTRICAS - BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MÉTRICAS DO MODELO ZERO-SHOT (Baseline) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91       161\n",
      "    positive       0.93      0.85      0.89       139\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.90      0.90      0.90       300\n",
      "weighted avg       0.90      0.90      0.90       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Obter os rótulos verdadeiros (ground truth)\n",
    "true_labels = list(df.head(AMOUNT_OF_REVIEWS_TO_CLASSIFY)['sentiment'])\n",
    "\n",
    "# 2. Obter os rótulos previstos\n",
    "predicted_labels = [item['predicted_label'] for item in model_classification_results]\n",
    "\n",
    "# 3. Relatório de classificação\n",
    "print(\"--- MÉTRICAS DO MODELO ZERO-SHOT (Baseline) ---\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e18a1",
   "metadata": {},
   "source": [
    "### FINE-TUNNING\n",
    "#### --- Preparação dos Dados ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce274682",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "sample_df = df.sample(n=TRAIN_SAMPLE_SIZE, random_state=42) \n",
    "\n",
    "# Converter 'positive'/'negative' para 0 e 1\n",
    "sample_df['label_num'] = sample_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Dividir os dados em Treino e Teste\n",
    "X = list(sample_df['review'])\n",
    "y = list(sample_df['label_num'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizar (converter o texto em números que o modelo entende)\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=256)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Pega todos os 'input_ids', 'attention_mask', etc.\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Adiciona o rótulo\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Criar os datasets de treino e teste\n",
    "train_dataset = IMDbDataset(train_encodings, y_train)\n",
    "test_dataset = IMDbDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf904f",
   "metadata": {},
   "source": [
    "#### TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2369406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 02:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.683700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.413700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.373400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.389400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.410100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.347400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.360400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.425700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.454600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.342900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.263800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.316300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.357800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.317600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.137900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.205300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.247200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.266200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.173100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.288700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.180900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.3375835294524829, metrics={'train_runtime': 153.8754, 'train_samples_per_second': 62.388, 'train_steps_per_second': 3.899, 'total_flos': 635843513548800.0, 'train_loss': 0.3375835294524829, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar o modelo pré-treinado (com uma \"cabeça\" de classificação em cima)\n",
    "# O num_labels=2 diz para ele se preparar para classificar entre 2 coisas (pos/neg)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fef71b",
   "metadata": {},
   "source": [
    "### MÉTRICAS - PÓS FINE-TUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107266a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MÉTRICAS DO MODELO FINE-TUNED ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       392\n",
      "    positive       0.90      0.90      0.90       408\n",
      "\n",
      "    accuracy                           0.90       800\n",
      "   macro avg       0.90      0.90      0.90       800\n",
      "weighted avg       0.90      0.90      0.90       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Fazer previsões no conjunto de teste\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# 2. As previsões saem como \"logits\", precisamos do rótulo final (0 ou 1)\n",
    "predicted_labels_tuned = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# 3. Pegar os rótulos verdadeiros do conjunto de teste\n",
    "true_labels_tuned = y_test\n",
    "\n",
    "# 4. Gerar o relatório de classificação\n",
    "print(\"--- MÉTRICAS DO MODELO FINE-TUNED ---\")\n",
    "print(classification_report(true_labels_tuned, predicted_labels_tuned, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be0722",
   "metadata": {},
   "source": [
    "## CONCLUSÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6fdbf",
   "metadata": {},
   "source": [
    "O objetivo deste projeto foi comparar a performance de um modelo de classificação Zero-Shot (Baseline) contra um modelo Fine-Tuned (Especialista) na tarefa de análise de sentimento.\n",
    "\n",
    "### Resultados:\n",
    "\n",
    "| MODELO | ESTRATÉGIA | MODELO BASE | ACURÁCIA | F1-SCORE (WEIGHTED) |\n",
    "| -------- | -------- | ----------- | -------- | ------------------- |\n",
    "| Baseline | Zero-Shot | ***facebook/bart-large-mnli*** | 90% | 0.9 |\n",
    "| Desafiante | Fine-Tuning | ***distilbert-base-uncased*** | 90% | 0.9 |\n",
    "\n",
    "### Análise:\n",
    "\n",
    "Surpreendentemente, o modelo Fine-Tuned (DistilBERT com 90% de acurácia) não superou o modelo Zero-Shot (BART-Large, também com 90%).\n",
    "Isso sugere que a tarefa de classificação de sentimento binário (positivo/negativo) é uma tarefa onde os modelos NLI de grande escala, como o BART-Large (406M de parâmetros), já possuem uma capacidade generalista extremamente alta.\n",
    "Mesmo treinando um modelo especialista (DistilBERT, 66M de parâmetros) com 4000 amostras, ele apenas conseguiu igualar a performance do modelo maior, que não recebeu nenhum treinamento específico para esta tarefa. Isso demonstra o poder dos modernos modelos de fundação.\n",
    "\n",
    "### Observação CPU x GPU\n",
    "\n",
    "O uso de GPU para execução do modelo **BART-Large** e treino do modelo **DistilBERT** apresentou uma redução no tempo de execução de 15 vezes frente ao uso de CPU para as mesmas tarefas. Isto deixa clara a importância do uso deste tipo de hardware no âmbito da NLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3feb2b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
