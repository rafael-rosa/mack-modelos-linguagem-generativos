{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1443906",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rafael-rosa/mack-modelos-linguagem-generativos/blob/main/movie_review_classif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## PROJETO FINAL DA DISCIPLINA ***MODELOS DE LINGUAGEM E GENERATIVOS***\n",
    "#### Prof. Rog√©rio de Oliveira\n",
    "Alunos: \n",
    "+ `Gildo Manzi da Silva - RA: 10329658`\n",
    "+ `Rafael da Silva Rosa - RA: 10746329`\n",
    "+ `Rog√©rio Goussain Labat - RA: 10746326`\n",
    "\n",
    "#### üé¨ Objetivo: Classificar reviews de filmes em ***\"Positivo\"*** ou ***\"Negativo\"*** üé≠\n",
    "#### üìä Origem dos dados: **IMDB / Kaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91713c45",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97be8bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: pandas==2.3.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: transformers==4.57.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (4.57.1)\n",
      "Requirement already satisfied: tf-keras==2.20.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.20.1)\n",
      "Requirement already satisfied: kagglehub in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.3.13)\n",
      "Requirement already satisfied: scikit-learn==1.7.2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
      "Requirement already satisfied: hf_xet==1.2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (1.11.0)\n",
      "Requirement already satisfied: evaluate==0.4.6 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from transformers==4.57.1->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tf-keras==2.20.1->-r requirements.txt (line 3)) (2.20.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from scikit-learn==1.7.2->-r requirements.txt (line 5)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from scikit-learn==1.7.2->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from scikit-learn==1.7.2->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from evaluate==0.4.6->-r requirements.txt (line 8)) (4.4.1)\n",
      "Requirement already satisfied: dill in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from evaluate==0.4.6->-r requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: xxhash in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from evaluate==0.4.6->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from evaluate==0.4.6->-r requirements.txt (line 8)) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (6.33.1)\n",
      "Requirement already satisfied: setuptools in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from requests->transformers==4.57.1->-r requirements.txt (line 2)) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.1.3)\n",
      "Requirement already satisfied: psutil in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from accelerate>=0.26.0->-r requirements.txt (line 7)) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from accelerate>=0.26.0->-r requirements.txt (line 7)) (2.8.0+cu129)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.45.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.6->-r requirements.txt (line 8)) (22.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.6->-r requirements.txt (line 8)) (0.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate==0.4.6->-r requirements.txt (line 8)) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate==0.4.6->-r requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate==0.4.6->-r requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.6->-r requirements.txt (line 8)) (1.22.0)\n",
      "Requirement already satisfied: rich in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.57.1->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate==0.4.6->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras==2.20.1->-r requirements.txt (line 3)) (0.1.2)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu129\n",
      "Requirement already satisfied: torch in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r other-requirements.txt (line 2)) (2.8.0+cu129)\n",
      "Requirement already satisfied: torchvision in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r other-requirements.txt (line 3)) (0.23.0+cu129)\n",
      "Requirement already satisfied: torchaudio in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from -r other-requirements.txt (line 4)) (2.8.0+cu129)\n",
      "Requirement already satisfied: filelock in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torch->-r other-requirements.txt (line 2)) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torchvision->-r other-requirements.txt (line 3)) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from torchvision->-r other-requirements.txt (line 3)) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r other-requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\dev\\python\\wks\\.venv\\lib\\site-packages (from jinja2->torch->-r other-requirements.txt (line 2)) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt\n",
    "!pip install -r other-requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4466f5",
   "metadata": {},
   "source": [
    "#### 1Ô∏è‚É£.1Ô∏è‚É£ IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6dc1ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\wks\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\dev\\python\\wks\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub \n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b78dc",
   "metadata": {},
   "source": [
    "#### 1Ô∏è‚É£.2Ô∏è‚É£ ENV VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c7bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT_OF_REVIEWS_TO_CLASSIFY = 300\n",
    "NUM_TRAIN_EPOCHS = 3 # 2 ou 3 √©pocas\n",
    "WARMUP_STEPS = 500 # Passos de aquecimento para o otimizador\n",
    "WEIGHT_DECAY = 0.01 # Decaimento de peso para o otimizador\n",
    "TRAIN_SAMPLE_SIZE = 4000 # Tamanho da amostra de treino\n",
    "MODEL_CHECKPOINT = \"distilbert-base-uncased\" # modelo leve para o fine-tuning - DistilBERT - r√°pido de treinar e tem √≥tima performance.\n",
    "KAGGLE_DATASET = \"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\" # Dataset do Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abebd431",
   "metadata": {},
   "source": [
    "#### 1Ô∏è‚É£.3Ô∏è‚É£ DATASET - IMDB MOVIE REVIEWS TO CLASSIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668f4b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\rafas\\.cache\\kagglehub\\datasets\\lakshmi25npathi\\imdb-dataset-of-50k-movie-reviews\\versions\\1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kind of drawn in by the erotic scenes, only to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Some films just simply should not be remade. T...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This movie made it into one of my top 10 most ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I remember this film,it was the first film i h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>An awful film! It must have been up against so...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5   Probably my all-time favorite movie, a story o...  positive\n",
       "6   I sure would like to see a resurrection of a u...  positive\n",
       "7   This show was an amazing, fresh & innovative i...  negative\n",
       "8   Encouraged by the positive comments about this...  negative\n",
       "9   If you like original gut wrenching laughter yo...  positive\n",
       "10  Phil the Alien is one of those quirky films wh...  negative\n",
       "11  I saw this movie when I was about 12 when it c...  negative\n",
       "12  So im not a big fan of Boll's work but then ag...  negative\n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative\n",
       "14  This a fantastic movie of three prisoners who ...  positive\n",
       "15  Kind of drawn in by the erotic scenes, only to...  negative\n",
       "16  Some films just simply should not be remade. T...  positive\n",
       "17  This movie made it into one of my top 10 most ...  negative\n",
       "18  I remember this film,it was the first film i h...  positive\n",
       "19  An awful film! It must have been up against so...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset IMDB reviews\n",
    "path = kagglehub.dataset_download(KAGGLE_DATASET)\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "df = pd.read_csv(path + \"/IMDB Dataset.csv\")    \n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611110a",
   "metadata": {},
   "source": [
    "#### 1Ô∏è‚É£.4Ô∏è‚É£ SET GPU CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5287fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 17 00:10:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 577.00                 Driver Version: 577.00         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   43C    P8              1W /   60W |    3881MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           34316      C   ...am Files\\Python313\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "GPU available? ‚úÖ\n",
      "GPU name: üéÆ NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Selected device: üñ•Ô∏è cuda:0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "print(f\"GPU available? {'‚úÖ' if torch.cuda.is_available() else '‚ùå'}\")\n",
    "print(f\"GPU name: {'üéÆ ' + torch.cuda.get_device_name(0) if torch.cuda.is_available() else '‚ö†Ô∏è None'}\")\n",
    "\n",
    "# Verify if the GPU (CUDA) is available\n",
    "# If it is, use \"cuda:0\" (the first GPU)\n",
    "# If not, use \"cpu\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Selected device: üñ•Ô∏è {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6424a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                      device=device)   # Use GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a058538",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Zero-Shot Classification \n",
    "#### 2Ô∏è‚É£.1Ô∏è‚É£ USE ***BART LARGE MNLI*** MODEL TO CLASSIFY MOVIE REVIEWS IN POSITIVE/NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fd4897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying 300 reviews...\n",
      "classification: positive with score 0.5315352082252502\n",
      "classification: positive with score 0.9874508380889893\n",
      "classification: positive with score 0.9743621349334717\n",
      "classification: negative with score 0.9753219485282898\n",
      "classification: positive with score 0.8379416465759277\n",
      "classification: positive with score 0.9739866256713867\n",
      "classification: positive with score 0.7787739038467407\n",
      "classification: negative with score 0.9267167448997498\n",
      "classification: negative with score 0.8084462881088257\n",
      "classification: positive with score 0.9694986939430237\n",
      "classification: negative with score 0.8875364065170288\n",
      "classification: negative with score 0.5397161841392517\n",
      "classification: negative with score 0.8973174691200256\n",
      "classification: negative with score 0.9752566814422607\n",
      "classification: positive with score 0.9951791167259216\n",
      "classification: negative with score 0.9860522150993347\n",
      "classification: negative with score 0.870980441570282\n",
      "classification: negative with score 0.980643093585968\n",
      "classification: positive with score 0.5455784201622009\n",
      "classification: negative with score 0.9686131477355957\n",
      "classification: positive with score 0.8618020415306091\n",
      "classification: negative with score 0.9835594892501831\n",
      "classification: positive with score 0.9763801097869873\n",
      "classification: negative with score 0.7895453572273254\n",
      "classification: negative with score 0.9744898676872253\n",
      "classification: negative with score 0.7800610065460205\n",
      "classification: positive with score 0.7609129548072815\n",
      "classification: negative with score 0.9933624267578125\n",
      "classification: negative with score 0.952426016330719\n",
      "classification: negative with score 0.6398021578788757\n",
      "classification: negative with score 0.8711929321289062\n",
      "classification: negative with score 0.6838829517364502\n",
      "classification: negative with score 0.9769946336746216\n",
      "classification: positive with score 0.6546924710273743\n",
      "classification: negative with score 0.8967628479003906\n",
      "classification: negative with score 0.968262791633606\n",
      "classification: negative with score 0.9708064198493958\n",
      "classification: negative with score 0.9838340282440186\n",
      "classification: negative with score 0.5115512013435364\n",
      "classification: negative with score 0.8882901072502136\n",
      "classification: negative with score 0.9466452598571777\n",
      "classification: positive with score 0.9922139048576355\n",
      "classification: negative with score 0.9135810136795044\n",
      "classification: negative with score 0.9038068056106567\n",
      "classification: negative with score 0.7097219228744507\n",
      "classification: positive with score 0.9429435729980469\n",
      "classification: negative with score 0.7758607268333435\n",
      "classification: negative with score 0.9797985553741455\n",
      "classification: negative with score 0.6387069821357727\n",
      "classification: negative with score 0.72232985496521\n",
      "classification: positive with score 0.8806262016296387\n",
      "classification: negative with score 0.9105001091957092\n",
      "classification: positive with score 0.9642540216445923\n",
      "classification: positive with score 0.9709616303443909\n",
      "classification: negative with score 0.904127836227417\n",
      "classification: negative with score 0.9686858654022217\n",
      "classification: positive with score 0.6155510544776917\n",
      "classification: negative with score 0.9842618703842163\n",
      "classification: positive with score 0.8144047856330872\n",
      "classification: positive with score 0.8548489809036255\n",
      "classification: negative with score 0.9138839244842529\n",
      "classification: negative with score 0.9549124240875244\n",
      "classification: positive with score 0.9695196747779846\n",
      "classification: negative with score 0.9865286350250244\n",
      "classification: negative with score 0.857109546661377\n",
      "classification: positive with score 0.9398780465126038\n",
      "classification: negative with score 0.5627765655517578\n",
      "classification: negative with score 0.7999480366706848\n",
      "classification: negative with score 0.9900487661361694\n",
      "classification: negative with score 0.5779743194580078\n",
      "classification: negative with score 0.6432791948318481\n",
      "classification: positive with score 0.5136581063270569\n",
      "classification: positive with score 0.7492625713348389\n",
      "classification: positive with score 0.9424378275871277\n",
      "classification: negative with score 0.8212389349937439\n",
      "classification: positive with score 0.9063794612884521\n",
      "classification: negative with score 0.6848577260971069\n",
      "classification: negative with score 0.979216992855072\n",
      "classification: negative with score 0.931253969669342\n",
      "classification: positive with score 0.937766432762146\n",
      "classification: positive with score 0.7717344164848328\n",
      "classification: negative with score 0.9505107998847961\n",
      "classification: negative with score 0.9464884996414185\n",
      "classification: negative with score 0.9381584525108337\n",
      "classification: negative with score 0.9920385479927063\n",
      "classification: negative with score 0.9597052335739136\n",
      "classification: negative with score 0.9566376209259033\n",
      "classification: negative with score 0.9103751182556152\n",
      "classification: negative with score 0.9776573181152344\n",
      "classification: negative with score 0.9448865652084351\n",
      "classification: positive with score 0.9684394598007202\n",
      "classification: negative with score 0.8419947624206543\n",
      "classification: positive with score 0.9849845170974731\n",
      "classification: positive with score 0.9219793677330017\n",
      "classification: negative with score 0.9696234464645386\n",
      "classification: positive with score 0.9377463459968567\n",
      "classification: negative with score 0.938559353351593\n",
      "classification: negative with score 0.9758031964302063\n",
      "classification: negative with score 0.990547776222229\n",
      "classification: positive with score 0.8898029327392578\n",
      "classification: positive with score 0.7710197567939758\n",
      "classification: negative with score 0.7180097103118896\n",
      "classification: positive with score 0.7665905356407166\n",
      "classification: positive with score 0.5583751201629639\n",
      "classification: negative with score 0.99588942527771\n",
      "classification: positive with score 0.8671374320983887\n",
      "classification: positive with score 0.8758025765419006\n",
      "classification: negative with score 0.9287956357002258\n",
      "classification: positive with score 0.9118618965148926\n",
      "classification: positive with score 0.9811205863952637\n",
      "classification: negative with score 0.9060414433479309\n",
      "classification: negative with score 0.5524750351905823\n",
      "classification: negative with score 0.9159803986549377\n",
      "classification: positive with score 0.9301763772964478\n",
      "classification: positive with score 0.8916941285133362\n",
      "classification: positive with score 0.9778469800949097\n",
      "classification: negative with score 0.7504372000694275\n",
      "classification: negative with score 0.9906818866729736\n",
      "classification: negative with score 0.997092068195343\n",
      "classification: negative with score 0.7877260446548462\n",
      "classification: positive with score 0.7872453331947327\n",
      "classification: positive with score 0.9547100067138672\n",
      "classification: negative with score 0.9330973625183105\n",
      "classification: negative with score 0.9621024131774902\n",
      "classification: positive with score 0.6219532489776611\n",
      "classification: negative with score 0.7346325516700745\n",
      "classification: negative with score 0.9894965887069702\n",
      "classification: negative with score 0.9817152619361877\n",
      "classification: positive with score 0.9419707655906677\n",
      "classification: negative with score 0.522548496723175\n",
      "classification: positive with score 0.9682331085205078\n",
      "classification: positive with score 0.8477234244346619\n",
      "classification: negative with score 0.9690763354301453\n",
      "classification: negative with score 0.9925141930580139\n",
      "classification: negative with score 0.9863703846931458\n",
      "classification: negative with score 0.9370627403259277\n",
      "classification: positive with score 0.530365526676178\n",
      "classification: negative with score 0.7050961852073669\n",
      "classification: positive with score 0.9351312518119812\n",
      "classification: negative with score 0.9183638691902161\n",
      "classification: positive with score 0.8716163635253906\n",
      "classification: negative with score 0.9729540348052979\n",
      "classification: negative with score 0.8982892036437988\n",
      "classification: positive with score 0.7885332107543945\n",
      "classification: negative with score 0.9753482937812805\n",
      "classification: positive with score 0.8660061359405518\n",
      "classification: positive with score 0.7998678088188171\n",
      "classification: positive with score 0.8785465955734253\n",
      "classification: negative with score 0.9637159705162048\n",
      "classification: negative with score 0.9636298418045044\n",
      "classification: positive with score 0.9727013111114502\n",
      "classification: negative with score 0.9261869192123413\n",
      "classification: negative with score 0.9165624380111694\n",
      "classification: positive with score 0.9136396050453186\n",
      "classification: negative with score 0.9686211347579956\n",
      "classification: positive with score 0.7118123173713684\n",
      "classification: negative with score 0.647377610206604\n",
      "classification: positive with score 0.9779937267303467\n",
      "classification: negative with score 0.8130889534950256\n",
      "classification: positive with score 0.7062105536460876\n",
      "classification: positive with score 0.95413738489151\n",
      "classification: negative with score 0.8694613575935364\n",
      "classification: negative with score 0.9858952164649963\n",
      "classification: positive with score 0.626420259475708\n",
      "classification: positive with score 0.8965221047401428\n",
      "classification: negative with score 0.9875519871711731\n",
      "classification: positive with score 0.9470730423927307\n",
      "classification: negative with score 0.9468609094619751\n",
      "classification: negative with score 0.9156225323677063\n",
      "classification: negative with score 0.9030003547668457\n",
      "classification: negative with score 0.9675089716911316\n",
      "classification: negative with score 0.6548981070518494\n",
      "classification: positive with score 0.8948072791099548\n",
      "classification: positive with score 0.968346357345581\n",
      "classification: negative with score 0.9725276827812195\n",
      "classification: negative with score 0.9254629611968994\n",
      "classification: positive with score 0.8429921865463257\n",
      "classification: negative with score 0.8543402552604675\n",
      "classification: positive with score 0.6740791201591492\n",
      "classification: negative with score 0.9543313384056091\n",
      "classification: positive with score 0.995683491230011\n",
      "classification: negative with score 0.7339789271354675\n",
      "classification: negative with score 0.9817540645599365\n",
      "classification: negative with score 0.9428430795669556\n",
      "classification: negative with score 0.949336588382721\n",
      "classification: negative with score 0.916711688041687\n",
      "classification: positive with score 0.633514404296875\n",
      "classification: negative with score 0.8997594714164734\n",
      "classification: positive with score 0.7148982882499695\n",
      "classification: negative with score 0.9697626233100891\n",
      "classification: negative with score 0.6549312472343445\n",
      "classification: negative with score 0.5921399593353271\n",
      "classification: positive with score 0.8711576461791992\n",
      "classification: positive with score 0.9353145956993103\n",
      "classification: negative with score 0.983170211315155\n",
      "classification: negative with score 0.9464544057846069\n",
      "classification: negative with score 0.95356684923172\n",
      "classification: negative with score 0.9630651473999023\n",
      "classification: positive with score 0.7413214445114136\n",
      "classification: negative with score 0.9523844122886658\n",
      "classification: positive with score 0.9854875206947327\n",
      "classification: positive with score 0.9664719104766846\n",
      "classification: positive with score 0.9356721043586731\n",
      "classification: positive with score 0.9860775470733643\n",
      "classification: negative with score 0.9786022901535034\n",
      "classification: positive with score 0.7470840811729431\n",
      "classification: negative with score 0.9770129323005676\n",
      "classification: negative with score 0.9556980729103088\n",
      "classification: negative with score 0.7602337598800659\n",
      "classification: positive with score 0.9912425875663757\n",
      "classification: negative with score 0.9801508784294128\n",
      "classification: negative with score 0.9898991584777832\n",
      "classification: negative with score 0.9499996900558472\n",
      "classification: positive with score 0.9223608374595642\n",
      "classification: negative with score 0.8913973569869995\n",
      "classification: positive with score 0.9155654907226562\n",
      "classification: positive with score 0.8402655720710754\n",
      "classification: negative with score 0.9911001920700073\n",
      "classification: positive with score 0.952743649482727\n",
      "classification: positive with score 0.7356402277946472\n",
      "classification: negative with score 0.9567664861679077\n",
      "classification: positive with score 0.6264700293540955\n",
      "classification: positive with score 0.9623210430145264\n",
      "classification: negative with score 0.9668238162994385\n",
      "classification: positive with score 0.970602810382843\n",
      "classification: negative with score 0.8119257688522339\n",
      "classification: positive with score 0.9854366779327393\n",
      "classification: positive with score 0.9728646874427795\n",
      "classification: positive with score 0.8378109335899353\n",
      "classification: negative with score 0.5024973750114441\n",
      "classification: negative with score 0.9745340943336487\n",
      "classification: positive with score 0.8493051528930664\n",
      "classification: positive with score 0.9354749321937561\n",
      "classification: positive with score 0.984382688999176\n",
      "classification: positive with score 0.8411732316017151\n",
      "classification: positive with score 0.9598950147628784\n",
      "classification: positive with score 0.9960821866989136\n",
      "classification: negative with score 0.9478418827056885\n",
      "classification: positive with score 0.5265161395072937\n",
      "classification: negative with score 0.9692608118057251\n",
      "classification: negative with score 0.9323176145553589\n",
      "classification: positive with score 0.932828962802887\n",
      "classification: negative with score 0.9662419557571411\n",
      "classification: positive with score 0.7864976525306702\n",
      "classification: negative with score 0.7775545716285706\n",
      "classification: positive with score 0.9841739535331726\n",
      "classification: negative with score 0.909726083278656\n",
      "classification: negative with score 0.7863821983337402\n",
      "classification: positive with score 0.9587776064872742\n",
      "classification: negative with score 0.9592648148536682\n",
      "classification: negative with score 0.9887470602989197\n",
      "classification: negative with score 0.9758186936378479\n",
      "classification: positive with score 0.5435454845428467\n",
      "classification: negative with score 0.9469598531723022\n",
      "classification: positive with score 0.9400620460510254\n",
      "classification: negative with score 0.8968518972396851\n",
      "classification: negative with score 0.8319740891456604\n",
      "classification: negative with score 0.984956681728363\n",
      "classification: positive with score 0.9526703357696533\n",
      "classification: negative with score 0.7187982201576233\n",
      "classification: positive with score 0.8921276330947876\n",
      "classification: negative with score 0.983717679977417\n",
      "classification: negative with score 0.9354703426361084\n",
      "classification: positive with score 0.6300220489501953\n",
      "classification: negative with score 0.9897423982620239\n",
      "classification: positive with score 0.7617590427398682\n",
      "classification: negative with score 0.958538830280304\n",
      "classification: negative with score 0.9967035055160522\n",
      "classification: negative with score 0.9843103885650635\n",
      "classification: positive with score 0.9831259846687317\n",
      "classification: negative with score 0.6248814463615417\n",
      "classification: positive with score 0.5030532479286194\n",
      "classification: negative with score 0.527319073677063\n",
      "classification: positive with score 0.620032548904419\n",
      "classification: negative with score 0.8462031483650208\n",
      "classification: positive with score 0.8841030597686768\n",
      "classification: negative with score 0.8006092309951782\n",
      "classification: positive with score 0.6513876914978027\n",
      "classification: negative with score 0.9751792550086975\n",
      "classification: negative with score 0.6935852766036987\n",
      "classification: positive with score 0.6372590065002441\n",
      "classification: negative with score 0.9938397407531738\n",
      "classification: negative with score 0.9725120663642883\n",
      "classification: negative with score 0.8933385610580444\n",
      "classification: positive with score 0.9439029097557068\n",
      "classification: negative with score 0.9631601572036743\n",
      "classification: negative with score 0.9010178446769714\n",
      "classification: positive with score 0.9527974128723145\n",
      "classification: positive with score 0.9008015990257263\n",
      "classification: positive with score 0.8985973000526428\n",
      "classification: positive with score 0.6148606538772583\n",
      "classification: positive with score 0.9345822930335999\n",
      "classification: positive with score 0.5360718965530396\n",
      "classification: negative with score 0.9669173359870911\n",
      "classification: positive with score 0.9867227673530579\n",
      "classification: negative with score 0.968547523021698\n",
      "classification: negative with score 0.9697657823562622\n",
      "classification: positive with score 0.8887796998023987\n",
      "classification: positive with score 0.9484139084815979\n",
      "classification: positive with score 0.8788615465164185\n"
     ]
    }
   ],
   "source": [
    "reviews = df['review'][:AMOUNT_OF_REVIEWS_TO_CLASSIFY].tolist()\n",
    "print(f\"Classifying {len(reviews)} reviews...\")\n",
    "\n",
    "model_classification_results = []\n",
    "candidate_labels = ['positive', 'negative']\n",
    "\n",
    "def data():\n",
    "    for i in reviews:\n",
    "        yield i\n",
    "\n",
    "# Batch processing using the pipeline for efficiency\n",
    "for result in classifier(data(), candidate_labels, batch_size=2):\n",
    "    print(\"classification:\", result['labels'][0], \"with score\", result['scores'][0])\n",
    "    model_classification_results.append({\n",
    "        'review': result['sequence'],\n",
    "        'predicted_label': result['labels'][0],\n",
    "        'score': result['scores'][0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2da16",
   "metadata": {},
   "source": [
    "#### 2Ô∏è‚É£.2Ô∏è‚É£ ERROR PERCENTAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7904f17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total incorrect predictions: 30 - Error percentage: 10.00%\n"
     ]
    }
   ],
   "source": [
    "counter_incorrect = 0\n",
    "for index, row in df.head(AMOUNT_OF_REVIEWS_TO_CLASSIFY).iterrows():\n",
    "    predicted = model_classification_results[index]['predicted_label']\n",
    "    actual_label = row['sentiment']\n",
    "    if predicted != actual_label:\n",
    "        # print(f\"Review {index+1} - Predicted: {predicted}, Actual: {actual_label}\")\n",
    "        counter_incorrect += 1\n",
    "        \n",
    "error_percentage = (counter_incorrect / AMOUNT_OF_REVIEWS_TO_CLASSIFY) * 100\n",
    "print(f\"Total incorrect predictions: {counter_incorrect} - Error percentage: {error_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf404306",
   "metadata": {},
   "source": [
    "#### 2Ô∏è‚É£.3Ô∏è‚É£ METRICS - BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f51eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- M√âTRICAS DO MODELO ZERO-SHOT (Baseline) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91       161\n",
      "    positive       0.93      0.85      0.89       139\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.90      0.90      0.90       300\n",
      "weighted avg       0.90      0.90      0.90       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Obter os r√≥tulos verdadeiros (ground truth)\n",
    "true_labels = list(df.head(AMOUNT_OF_REVIEWS_TO_CLASSIFY)['sentiment'])\n",
    "\n",
    "# 2. Obter os r√≥tulos previstos\n",
    "predicted_labels = [item['predicted_label'] for item in model_classification_results]\n",
    "\n",
    "# 3. Relat√≥rio de classifica√ß√£o\n",
    "print(\"--- M√âTRICAS DO MODELO ZERO-SHOT (Baseline) ---\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e18a1",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ FINE-TUNNING\n",
    "#### 3Ô∏è‚É£.1Ô∏è‚É£ DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce274682",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "sample_df = df.sample(n=TRAIN_SAMPLE_SIZE, random_state=42) \n",
    "\n",
    "# Convert 'positive'/'negative' to 0 and 1\n",
    "sample_df['label_num'] = sample_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Split the data into Train and Test\n",
    "X = list(sample_df['review'])\n",
    "y = list(sample_df['label_num'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize (convert text into numbers the model understands)\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=256)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f9274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get all 'input_ids', 'attention_mask', etc.\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Add label\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, y_train)\n",
    "test_dataset = IMDbDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf904f",
   "metadata": {},
   "source": [
    "#### 3Ô∏è‚É£.2Ô∏è‚É£ TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2369406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 02:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>0.431061</td>\n",
       "      <td>0.813750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.333066</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.313103</td>\n",
       "      <td>0.897500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.35445082326730093, metrics={'train_runtime': 169.738, 'train_samples_per_second': 56.558, 'train_steps_per_second': 3.535, 'total_flos': 635843513548800.0, 'train_loss': 0.35445082326730093, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Used by trainer to compute metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Load the pre-trained model (with a classification \"head\" on top)\n",
    "# The num_labels=2 tells it to prepare to classify between 2 things (pos/neg)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)\n",
    "\n",
    "# Uma pr√°tica melhor √© avaliar o modelo ao final de cada √©poca e salvar apenas o melhor.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",            # Avaliar a cada √©poca\n",
    "    save_strategy=\"epoch\",            # Salvar a cada √©poca\n",
    "    load_best_model_at_end=True       # Carregar o melhor modelo no final\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fef71b",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£.3Ô∏è‚É£ METRICS - AFTER FINE-TUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9107266a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINE-TUNED MODEL METRICS ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.90       392\n",
      "    positive       0.91      0.88      0.90       408\n",
      "\n",
      "    accuracy                           0.90       800\n",
      "   macro avg       0.90      0.90      0.90       800\n",
      "weighted avg       0.90      0.90      0.90       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Predictions come out as \"logits\", we need the final label (0 or 1)\n",
    "predicted_labels_tuned = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Get the true labels from the test set\n",
    "true_labels_tuned = y_test\n",
    "\n",
    "# Generate the classification report\n",
    "print(\"--- FINE-TUNED MODEL METRICS ---\")\n",
    "print(classification_report(true_labels_tuned, predicted_labels_tuned, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be0722",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ CONCLUS√ÉO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6fdbf",
   "metadata": {},
   "source": [
    "O objetivo deste projeto foi comparar a performance de um modelo de classifica√ß√£o Zero-Shot (Baseline) contra um modelo Fine-Tuned (Especialista) na tarefa de an√°lise de sentimento.\n",
    "\n",
    "### Resultados:\n",
    "\n",
    "| MODELO | ESTRAT√âGIA | MODELO BASE | ACUR√ÅCIA | F1-SCORE (WEIGHTED) |\n",
    "| -------- | -------- | ----------- | -------- | ------------------- |\n",
    "| Baseline | Zero-Shot | ***facebook/bart-large-mnli*** | 90% | 0.9 |\n",
    "| Desafiante | Fine-Tuning | ***distilbert-base-uncased*** | 90% | 0.90 |\n",
    "\n",
    "### An√°lise:\n",
    "\n",
    "Surpreendentemente, o modelo Fine-Tuned (DistilBERT com 90% de acur√°cia) n√£o superou o modelo Zero-Shot (BART-Large, tamb√©m com 90%).\n",
    "Isso sugere que a tarefa de classifica√ß√£o de sentimento bin√°rio (positivo/negativo) √© uma tarefa onde os modelos NLI de grande escala, como o BART-Large (406M de par√¢metros), j√° possuem uma capacidade generalista extremamente alta.\n",
    "Mesmo treinando um modelo especialista (DistilBERT, 66M de par√¢metros) com 4000 amostras, ele apenas conseguiu igualar a performance do modelo maior, que n√£o recebeu nenhum treinamento espec√≠fico para esta tarefa. Isso demonstra o poder dos modernos modelos de funda√ß√£o.\n",
    "\n",
    "### Observa√ß√£o CPU x GPU\n",
    "\n",
    "O uso de GPU para execu√ß√£o do modelo **BART-Large** e treino do modelo **DistilBERT** apresentou uma redu√ß√£o no tempo de execu√ß√£o de 15 vezes frente ao uso de CPU para as mesmas tarefas. Isto deixa clara a import√¢ncia do uso deste tipo de hardware no √¢mbito da NLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3feb2b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
