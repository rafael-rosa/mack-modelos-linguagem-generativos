# Projeto: Classifica√ß√£o Zero-Shot vs. Fine-Tuning para An√°lise de Sentimento

Este reposit√≥rio cont√©m o projeto final da disciplina **"Modelos de Linguagem e Generativos"**, focado na compara√ß√£o de duas t√©cnicas centrais de PLN: Classifica√ß√£o Zero-Shot e Fine-Tuning.

### Programa de p√≥s-gradua√ß√£o em Computa√ß√£o Aplicada - Metrado Profissional - Mackenzie
* `Prof. Rog√©rio de Oliveira`
### Autores
* `Gildo Manzi da Silva` - RA: 10329658
* `Rafael da Silva Rosa` - RA: 10746329
* `Rog√©rio Goussain Labat` - RA: 10746326

---

## üéØ Introdu√ß√£o

O objetivo deste projeto √© comparar o desempenho de duas abordagens distintas para a tarefa de an√°lise de sentimento (classificar reviews de filmes como "positivos" ou "negativos") usando um dataset com reviews do IMDB disponibilizado no Kaggle.

As duas abordagens comparadas s√£o:

1.  **Classifica√ß√£o Zero-Shot (Baseline):** Utiliza um modelo generalista (`facebook/bart-large-mnli`) que classifica o texto sem nunca ter sido treinado especificamente nesta tarefa.
2.  **Fine-Tuning (Desafiante):** Utiliza um modelo especialista (`distilbert-base-uncased`) que √© treinado (ajustado) em milhares de exemplos espec√≠ficos da tarefa.

A hip√≥tese inicial √© que o modelo Fine-Tuned, por ser especialista, superaria o modelo Zero-Shot generalista.

---

## üèÜ Resultados Principais

Contrariando a hip√≥tese inicial, o modelo Zero-Shot (Baseline) apresentou um desempenho similar ao modelo especialista Fine-Tuned.

| Estrat√©gia | Modelo Base | Acur√°cia | F1-Score (Weighted) |
| :--- | :--- | :--- | :--- |
| **Baseline (Zero-Shot)** | `facebook/bart-large-mnli` | **90%** | **0.90** |
| **Desafiante (Fine-Tuned)**| `distilbert-base-uncased`| **90%** | **0.90** |

**An√°lise da Conclus√£o:**
Acreditamos que para uma tarefa bin√°ria simples como esta, o poder generalista de um modelo de funda√ß√£o de grande escala j√° √© suficiente para atingir uma performance muito alta, alcan√ßando o mesmo resultado de um modelo treinado para ser especializado na tarefa.
1.  O modelo **Zero-Shot (BART-Large)** possui 406M de par√¢metros e foi treinado em uma tarefa (NLI) que se traduz muito bem para a an√°lise de sentimento.
2.  O modelo **Fine-Tuned (DistilBERT)** √© significativamente menor (66M de par√¢metros).

---

## üß† Referencial Te√≥rico

### Classifica√ß√£o Zero-Shot
A classifica√ß√£o Zero-Shot √© uma t√©cnica onde um modelo pode classificar dados em categorias que n√£o viu durante o treinamento. No contexto de PLN, isso √© comumente alcan√ßado "reformulando" a tarefa de classifica√ß√£o como uma tarefa de **Infer√™ncia de Linguagem Natural (NLI)**. O modelo avalia a probabilidade de uma "premissa" (o review do filme) implicar logicamente uma "hip√≥tese" (ex: "Este texto √© positivo"). O modelo `bart-large-mnli` √© pr√©-treinado na tarefa Multi-Genre NLI (MNLI), tornando-o ideal para isso.

### Fine-Tuning
Fine-Tuning (Ajuste Fino) √© o processo de pegar um modelo de funda√ß√£o pr√©-treinado (como o `DistilBERT`, que foi treinado para "entender" a linguagem em geral) e trein√°-lo um pouco mais em um conjunto de dados espec√≠fico e com uma tarefa espec√≠fica. Uma "cabe√ßa de classifica√ß√£o" √© adicionada ao topo do modelo, e seus pesos s√£o ajustados para se especializarem na nova tarefa (neste caso, classificar reviews do IMDB).

---

## üß™ Metodologia

O projeto foi conduzido em duas etapas principais, ambas utilizando o dataset [IMDb Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) baixado via `kagglehub`.

### 1. Baseline: Modelo Zero-Shot
* **Modelo:** `facebook/bart-large-mnli` (406M de par√¢metros).
* **Processo:** 300 reviews do dataset foram selecionados aleatoriamente.
* **Execu√ß√£o:** O modelo `pipeline` foi carregado na GPU (`cuda:0`) e classificou as 300 amostras com os r√≥tulos `['positive', 'negative']`.
* **M√©tricas:** Um `classification_report` (Acur√°cia, Precis√£o, Recall, F1-Score) foi gerado comparando as previs√µes com os r√≥tulos reais.

### 2. Desafiante: Modelo Fine-Tuned
* **Modelo:** `distilbert-base-uncased` (66M de par√¢metros).
* **Processo:**
    1.  Uma amostra de 4000 reviews foi selecionada do dataset.
    2.  Os dados foram divididos em 80% para treino (3200 amostras) e 20% para teste (800 amostras).
    3.  O `AutoTokenizer` foi usado para preparar os dados.
    4.  O modelo foi treinado por 3 √©pocas usando o `Trainer` da Hugging Face, com avalia√ß√£o ao final de cada √©poca.
    5.  Foi configurado para salvar apenas o melhor modelo (`load_best_model_at_end=True`), que se revelou o da √âpoca 2, evitando overfitting que ocorreu na √âpoca 3.
* **M√©tricas:** As mesmas m√©tricas foram calculadas no conjunto de teste de 800 amostras.

---

## üöÄ Instru√ß√µes de Uso

### Pr√©-requisitos
* Python 3.10+
* Uma GPU NVIDIA com CUDA (essencial para performance). O projeto foi testado com CUDA 12.9.
* Git

### 1. Clonar o Reposit√≥rio
```bash
git clone [https://github.com/rafael-rosa/mack-modelos-linguagem-generativos.git](https://github.com/rafael-rosa/mack-modelos-linguagem-generativos.git)
cd mack-modelos-linguagem-generativos
```

### 2. Configurar o Ambiente Virtual

```bash
python -m venv .venv

# No Windows
.venv\Scripts\activate

# No Linux/macOS
source .venv/bin/activate
```

### 3. Instalar as Depend√™ncias

O projeto usa dois arquivos de requisitos. O other-requirements.txt for√ßa a instala√ß√£o do PyTorch com o suporte a CUDA correto.

```bash
pip install --upgrade pip
pip install -r requirements.txt
pip install -r other-requirements.txt
```

### 4. Executar o Notebook

Abra o notebook `movie_review_classif.ipynb` em seu editor de c√≥digo preferido (como VS Code ou Jupyter Lab) e execute as c√©lulas na ordem.

    Nota: Na primeira execu√ß√£o, a biblioteca kagglehub far√° o download do dataset (aprox. 64MB) e os modelos ser√£o baixados (BART-Large tem ~1.6GB e DistilBERT ~268MB). Os checkpoints do modelo treinado ser√£o salvos na pasta ./results.

### üìÇ Estrutura do Projeto

<pre>
.
‚îú‚îÄ‚îÄ .venv/                      # Ambiente virtual (ignorado)
‚îú‚îÄ‚îÄ results/                    # Checkpoints do modelo Fine-Tuned (gerado)
‚îú‚îÄ‚îÄ logs/                       # Logs de treino (gerado)
‚îú‚îÄ‚îÄ movie_review_classif.ipynb  # O notebook principal do projeto
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias de Python
‚îú‚îÄ‚îÄ other-requirements.txt      # Depend√™ncias do PyTorch (GPU)
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
</pre>