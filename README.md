# Projeto: Zero-Shot vs. Fine-Tuning para classifica√ß√£o de G√™nero/T√≥pico a partir de um texto

Este reposit√≥rio cont√©m o projeto final da disciplina **"Modelos de Linguagem e Generativos"**, focado na compara√ß√£o de duas t√©cnicas centrais de PLN: Classifica√ß√£o Zero-Shot e Fine-Tuning.

### Programa de p√≥s-gradua√ß√£o em Computa√ß√£o Aplicada - Mestrado Profissional - Mackenzie
* `Prof. Rog√©rio de Oliveira`
### Autores
* `Gildo Manzi da Silva` - RA: 10329658
* `Rafael da Silva Rosa` - RA: 10746329
* `Rog√©rio Goussain Labat` - RA: 10746326

---

## üéØ Introdu√ß√£o

O objetivo deste projeto √© comparar o desempenho de duas abordagens distintas para uma tarefa de an√°lise de texto (determinar o g√™nero de um filme a partir de sua sinopse) usando um dataset constru√≠do com dados do IMDB e do OMDB.

As duas abordagens comparadas s√£o:

1.  **Classifica√ß√£o Zero-Shot (Baseline):** Utiliza um modelo generalista (`facebook/bart-large-mnli`) que classifica o texto sem nunca ter sido treinado especificamente nesta tarefa.
2.  **Fine-Tuning (Desafiante):** Utiliza um modelo especialista (`distilbert-base-uncased`) que √© treinado (ajustado) em milhares de exemplos espec√≠ficos da tarefa. Importante mencionar que **implementamos uma Custom Loss Function** com pesos inversamente proporcionais √† frequ√™ncia das classes para mitigar o vi√©s do modelo em dire√ß√£o √†s classes majorit√°rias.

A hip√≥tese inicial √© que o modelo Fine-Tuned, por ser especialista, superaria o modelo Zero-Shot generalista.

---

## üèÜ Resultados Principais

A tarefa de classifica√ß√£o multiclasse exp√¥s as limita√ß√µes da abordagem Zero-Shot e a for√ßa do Fine-Tuning:

| MODELO | ESTRAT√âGIA | MODELO BASE | ACUR√ÅCIA | F1-SCORE (WEIGHTED) | TEMPO DE INFER√äNCIA | 
| -------- | -------- | ----------- | -------- | ------------------- | ------------------- |
| Baseline | Zero-Shot | ***facebook/bart-large-mnli*** | **15%** | 0.15 | Alto (lento) |
| Desafiante | Fine-Tuning | ***distilbert-base-uncased*** | **42%** | 0.42 | Baixo (R√°pido) |

**An√°lise da Conclus√£o:**
1.  **O Desafio da Ambiguidade:** Em um cen√°rio com 27 classes poss√≠veis, a fronteira entre g√™neros como "A√ß√£o", "Aventura" e "Crime" √© t√™nue. O modelo Zero-Shot, por ser generalista, tende a se confundir com a sobreposi√ß√£o de temas. O modelo Fine-Tuned, por outro lado, aprendeu as nuances espec√≠ficas de como *este dataset* define cada g√™nero.

2.  **Efici√™ncia Computacional:** A abordagem Zero-Shot exigiu que o modelo processasse cada sinopse comparando-a com todas as etiquetas candidatas, tornando a infer√™ncia significativamente mais lenta. O modelo Fine-Tuned (DistilBERT), al√©m de ser arquiteturalmente mais leve (66M vs 406M par√¢metros), realiza a classifica√ß√£o em uma √∫nica passagem direta (forward pass), sendo ideal para ambientes de produ√ß√£o.

### Veredito Final
Para tarefas complexas de classifica√ß√£o multiclasse com defini√ß√µes de dom√≠nio espec√≠ficas, o **Fine-Tuning √© indispens√°vel**. Embora o Zero-Shot seja uma ferramenta poderosa para prototipagem r√°pida e situa√ß√µes de "cold start" (sem dados), ele n√£o consegue competir com a precis√£o e a efici√™ncia de um modelo especialista treinado (mesmo que menor) quando dados rotulados est√£o dispon√≠veis.

---

## üß† Referencial Te√≥rico

### Classifica√ß√£o Zero-Shot
A classifica√ß√£o Zero-Shot √© uma t√©cnica onde um modelo pode classificar dados em categorias que n√£o viu durante o treinamento. No contexto de PLN, isso √© comumente alcan√ßado "reformulando" a tarefa de classifica√ß√£o como uma tarefa de **Infer√™ncia de Linguagem Natural (NLI)**. O modelo avalia a probabilidade de uma "premissa" (a sinopse do filme) implicar logicamente uma "hip√≥tese" (ex: "Este filme √© um Drama"). O modelo `bart-large-mnli` √© pr√©-treinado na tarefa Multi-Genre NLI (MNLI), tornando-o ideal para isso.

### Fine-Tuning
Fine-Tuning (Ajuste Fino) √© o processo de pegar um modelo de funda√ß√£o pr√©-treinado (como o `DistilBERT`, que foi treinado para "entender" a linguagem em geral) e trein√°-lo um pouco mais em um conjunto de dados espec√≠fico e com uma tarefa espec√≠fica. Uma "cabe√ßa de classifica√ß√£o" √© adicionada ao topo do modelo, e seus pesos s√£o ajustados para se especializarem na nova tarefa (neste caso, determinar o g√™nero do filme a partir do plot).

---

## üß™ Metodologia

O projeto foi conduzido em tr√™s etapas principais:

### 1. Coleta de dados e prepara√ß√£o dos dados
* Download do dataset com ID's dos filmes no site do IMDB: https://datasets.imdbws.com/
* Coleta das sinopses e g√™neros dos filmes via API do OMDB: https://www.omdbapi.com/
* Compila√ß√£o de um dataset √∫nico com os dados coletados
* Remo√ß√£o de nulos e normaliza√ß√£o dos dados

### 2. Baseline: Modelo Zero-Shot
* **Modelo:** `facebook/bart-large-mnli` (406M de par√¢metros).
* **Processo:** 500 sinopses do dataset foram selecionadas aleatoriamente.
* **Execu√ß√£o:** O modelo `pipeline` foi carregado na GPU (`cuda:0`) e classificou as 500 amostras com 27 r√≥tulos poss√≠veis `['DOCUMENTARY', 'COMEDY', 'DRAMA', 'SHORT', 'WESTERN', 'THRILLER', 'ANIMATION', 'MUSIC', 'CRIME', 'SCI-FI', 'HORROR', 'TALK-SHOW', 'FAMILY', 'ACTION', 'MYSTERY', 'BIOGRAPHY', 'REALITY-TV', 'NEWS', 'FANTASY', 'ROMANCE', 'MUSICAL', 'SPORT', 'HISTORY', 'GAME-SHOW', 'ADVENTURE', 'WAR', 'ADULT']`.
* **M√©tricas:** Um `classification_report` (Acur√°cia, Precis√£o, Recall, F1-Score) foi gerado comparando as previs√µes com os r√≥tulos reais.

### 3. Desafiante: Modelo Fine-Tuned
* **Modelo:** `distilbert-base-uncased` (66M de par√¢metros).
* **Processo:**
    1.  Uma amostra de 1500 plots foi selecionada do dataset.
    2.  Os dados foram divididos em 60% para treino e 40% para teste.
    3.  O `AutoTokenizer` foi usado para preparar os dados.
    4.  O modelo foi treinado por 10 √©pocas usando um `Trainer` customizado com suporte a fun√ß√£o de perdas.
    5.  Foi configurado para salvar apenas o melhor modelo (`load_best_model_at_end=True`) evitando overfitting.
* **M√©tricas:** As mesmas m√©tricas foram calculadas no conjunto de teste.

---

## üöÄ Instru√ß√µes de Uso

### Pr√©-requisitos
* Python 3.13+
* Uma GPU NVIDIA com CUDA (essencial para performance). O projeto foi testado com CUDA 12.9.
* Git

### 1. Clonar o Reposit√≥rio
```bash
git clone [https://github.com/rafael-rosa/mack-modelos-linguagem-generativos.git](https://github.com/rafael-rosa/mack-modelos-linguagem-generativos.git)
cd mack-modelos-linguagem-generativos
```

### 2. Configurar o Ambiente Virtual

```bash
python -m venv .venv

# No Windows
.venv\Scripts\activate

# No Linux/macOS
source .venv/bin/activate
```

### 3. Instalar as Depend√™ncias

O projeto usa dois arquivos de requisitos. O other-requirements.txt for√ßa a instala√ß√£o do PyTorch com o suporte a CUDA correto.

```bash
pip install --upgrade pip
pip install -r requirements.txt
pip install -r other-requirements.txt
```

### 4. Executar o Notebook

Abra o notebook `movie_plot_classifier.ipynb` em seu editor de c√≥digo preferido (como VS Code ou Jupyter Lab) e execute as c√©lulas na ordem.

    Nota: Na primeira execu√ß√£o, os modelos ser√£o baixados (BART-Large tem ~1.6GB e DistilBERT ~268MB) e os checkpoints do modelo treinado ser√£o salvos na pasta ./results.

### ‚ö†Ô∏è IMPORTANTE: Execu√ß√£o via Google Colab

Executar o notebook via Google Colab poder√° exigir o fornecimento de uma API Key do `wandb.ai` no passo **3.2 (Treinamento)**. Obtenha uma API Key criando uma conta em https://wandb.ai/authorize?ref=models e forne√ßa a chave diretamente no Colab no momento em que for solicitada. **O n√£o fornecimento da API Key implicar√° em erro de execu√ß√£o.**



### üìÇ Estrutura do Projeto

<pre>
.
‚îú‚îÄ‚îÄ .venv/                          # Ambiente virtual (ignorado)
‚îú‚îÄ‚îÄ coleta_dados/                   # Processos de coleta de dados
    ‚îú‚îÄ‚îÄ movie_plot_gathering.ipynb  # Notebok para ler IDs dos filmes e coletar dados via API do OMDB
    ‚îú‚îÄ‚îÄ /imdb_dataset/  
        ‚îî‚îÄ‚îÄ title.ratings.tsv       # Dataset com IDs de filmes do IMDB
    ‚îî‚îÄ‚îÄ /out/                       # Dados dos filmes coletados via API do OMDB (por√ß√µes de mil)
‚îú‚îÄ‚îÄ data_prep/
    ‚îî‚îÄ‚îÄ create_movies_dataset.ipynb # Compila os dados coletados e um √∫nico dataset e faz a prepara√ß√£o dos dados
‚îú‚îÄ‚îÄ movies_dataset/
    ‚îî‚îÄ‚îÄ movie_plots_dataset.csv     # Dataset final para uso nos modelos
‚îú‚îÄ‚îÄ results/                        # Checkpoints do modelo Fine-Tuned (gerado)
‚îú‚îÄ‚îÄ logs/                           # Logs de treino (gerado)
‚îú‚îÄ‚îÄ movie_plot_classifier.ipynb     # O notebook principal do projeto
‚îú‚îÄ‚îÄ requirements.txt                # Depend√™ncias de Python
‚îú‚îÄ‚îÄ other-requirements.txt          # Depend√™ncias do PyTorch (GPU)
‚îî‚îÄ‚îÄ README.md                       # Este arquivo
</pre>


---

# üí≤Aplica√ß√µes pr√°ticas reais - Plano de neg√≥cios

Duas sugest√µes de aplica√ß√µes poss√≠veis para o projeto, conectando diretamente as tecnologias objetos do teste (***Zero-Shot e Fine-Tuning***) com cen√°rios de neg√≥cio tang√≠veis:

## 1Ô∏è‚É£. Cen√°rio "Streaming & M√≠dia": ***Cataloga√ß√£o Autom√°tica de Conte√∫do (Metadata Tagging)***

Este √© o uso mais direto do seu dataset de filmes, mas aplicado a plataformas como Globoplay, Spotify ou Marketplaces de E-books (Kindle).

**O Problema:** Uma plataforma recebe milhares de novos conte√∫dos (v√≠deos de parceiros, podcasts, livros indie) por dia. Classificar manualmente se um v√≠deo √© "Esportes", "E-Sports" ou "Lazer" √© lento e caro. Al√©m disso, surgem novos g√™neros o tempo todo (ex: "True Crime" n√£o era uma categoria forte h√° 10 anos).

**A Aplica√ß√£o H√≠brida:**

+ **Fine-Tuning**: O modelo treinado varre todo o cat√°logo existente e novos uploads di√°rios, classificando-os rapidamente nas categorias "pai" (A√ß√£o, Drama, Com√©dia). Isso garante velocidade e baixo custo de nuvem.
+ **Zero-Shot**: A equipe de marketing quer criar uma cole√ß√£o tempor√°ria para o Halloween ou para uma tend√™ncia do TikTok (ex: "Dark Academia"). Eles n√£o t√™m dados para treinar um modelo. Eles usam o Zero-Shot para re-classificar o conte√∫do apenas buscando essa tag espec√≠fica.

#### üìà **Valor de Neg√≥cio:** 

+ `Redu√ß√£o` de custo operacional (menos humanos tagueando)
+ `+ Agilidade` de Marketing (criar vitrines tem√°ticas em minutos, n√£o semanas).

## 2Ô∏è‚É£. Cen√°rio "Atendimento ao Cliente": ***Roteamento Inteligente de Tickets (Smart Triage)***

Trocamos "Sinopse do Filme" por "Descri√ß√£o do Problema do Cliente" e "G√™nero" por "Departamento Respons√°vel.

**O Problema:** Uma empresa de Telecom ou um Banco recebe milhares de e-mails/chamados por dia. Atualmente, um humano l√™ e decide: "Isso vai para o Financeiro", "Isso √© Suporte T√©cnico", "Isso √© Vendas". Esse humano √© um gargalo..

**A Aplica√ß√£o:**

+ `Fine-Tuning (Alta Efici√™ncia)`: O modelo √© treinado com o hist√≥rico de chamados dos √∫ltimos 2 anos. Exemplo: `"Minha fatura veio cobrando o valor errado." ‚Üí Modelo prev√™: Financeiro (99% confian√ßa).`

#### üìà **Valor de Neg√≥cio:** 

+ `Fine-Tuning:` Automatiza 80-90% da triagem (reduzindo tempo de resposta de horas para segundos).
