# Projeto: Classifica√ß√£o Zero-Shot vs. Fine-Tuning para An√°lise de Sentimento

Este reposit√≥rio cont√©m o projeto final da disciplina **"Modelos de Linguagem e Generativos"**, focado na compara√ß√£o de duas t√©cnicas centrais de PLN: Classifica√ß√£o Zero-Shot e Fine-Tuning.

### Programa de p√≥s-gradua√ß√£o em Computa√ß√£o Aplicada - Metrado Profissional - Mackenzie
* `Prof. Rog√©rio de Oliveira`
### Autores
* `Gildo Manzi da Silva` - RA: 10329658
* `Rafael da Silva Rosa` - RA: 10746329
* `Rog√©rio Goussain Labat` - RA: 10746326

---

## üéØ Introdu√ß√£o

O objetivo deste projeto √© comparar o desempenho de duas abordagens distintas para a tarefa de an√°lise de sentimento (classificar reviews de filmes como "positivos" ou "negativos") usando um dataset com reviews do IMDB disponibilizado no Kaggle.

As duas abordagens comparadas s√£o:

1.  **Classifica√ß√£o Zero-Shot (Baseline):** Utiliza um modelo generalista (`facebook/bart-large-mnli`) que classifica o texto sem nunca ter sido treinado especificamente nesta tarefa.
2.  **Fine-Tuning (Desafiante):** Utiliza um modelo especialista (`distilbert-base-uncased`) que √© treinado (ajustado) em milhares de exemplos espec√≠ficos da tarefa.

A hip√≥tese inicial √© que o modelo Fine-Tuned, por ser especialista, superaria o modelo Zero-Shot generalista.

---

## üèÜ Resultados Principais

Contrariando a hip√≥tese inicial, o modelo Zero-Shot (Baseline) apresentou um desempenho similar ao modelo especialista Fine-Tuned.

| Estrat√©gia | Modelo Base | Acur√°cia | F1-Score (Weighted) |
| :--- | :--- | :--- | :--- |
| **Baseline (Zero-Shot)** | `facebook/bart-large-mnli` | **90%** | **0.90** |
| **Desafiante (Fine-Tuned)**| `distilbert-base-uncased`| **90%** | **0.90** |

**An√°lise da Conclus√£o:**
Acreditamos que para uma tarefa bin√°ria simples como esta, o poder generalista de um modelo de funda√ß√£o de grande escala j√° √© suficiente para atingir uma performance muito alta, alcan√ßando o mesmo resultado de um modelo treinado para ser especializado na tarefa.
1.  O modelo **Zero-Shot (BART-Large)** possui 406M de par√¢metros e foi treinado em uma tarefa (NLI) que se traduz muito bem para a an√°lise de sentimento.
2.  O modelo **Fine-Tuned (DistilBERT)** √© significativamente menor (66M de par√¢metros).

---

## üß† Referencial Te√≥rico

### Classifica√ß√£o Zero-Shot
A classifica√ß√£o Zero-Shot √© uma t√©cnica onde um modelo pode classificar dados em categorias que n√£o viu durante o treinamento. No contexto de PLN, isso √© comumente alcan√ßado "reformulando" a tarefa de classifica√ß√£o como uma tarefa de **Infer√™ncia de Linguagem Natural (NLI)**. O modelo avalia a probabilidade de uma "premissa" (o review do filme) implicar logicamente uma "hip√≥tese" (ex: "Este texto √© positivo"). O modelo `bart-large-mnli` √© pr√©-treinado na tarefa Multi-Genre NLI (MNLI), tornando-o ideal para isso.

### Fine-Tuning
Fine-Tuning (Ajuste Fino) √© o processo de pegar um modelo de funda√ß√£o pr√©-treinado (como o `DistilBERT`, que foi treinado para "entender" a linguagem em geral) e trein√°-lo um pouco mais em um conjunto de dados espec√≠fico e com uma tarefa espec√≠fica. Uma "cabe√ßa de classifica√ß√£o" √© adicionada ao topo do modelo, e seus pesos s√£o ajustados para se especializarem na nova tarefa (neste caso, classificar reviews do IMDB).

---

## üß™ Metodologia

O projeto foi conduzido em duas etapas principais, ambas utilizando o dataset [IMDb Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) baixado via `kagglehub`.

### 1. Baseline: Modelo Zero-Shot
* **Modelo:** `facebook/bart-large-mnli` (406M de par√¢metros).
* **Processo:** 300 reviews do dataset foram selecionados aleatoriamente.
* **Execu√ß√£o:** O modelo `pipeline` foi carregado na GPU (`cuda:0`) e classificou as 300 amostras com os r√≥tulos `['positive', 'negative']`.
* **M√©tricas:** Um `classification_report` (Acur√°cia, Precis√£o, Recall, F1-Score) foi gerado comparando as previs√µes com os r√≥tulos reais.

### 2. Desafiante: Modelo Fine-Tuned
* **Modelo:** `distilbert-base-uncased` (66M de par√¢metros).
* **Processo:**
    1.  Uma amostra de 4000 reviews foi selecionada do dataset.
    2.  Os dados foram divididos em 80% para treino (3200 amostras) e 20% para teste (800 amostras).
    3.  O `AutoTokenizer` foi usado para preparar os dados.
    4.  O modelo foi treinado por 3 √©pocas usando o `Trainer` da Hugging Face, com avalia√ß√£o ao final de cada √©poca.
    5.  Foi configurado para salvar apenas o melhor modelo (`load_best_model_at_end=True`), que se revelou o da √âpoca 2, evitando overfitting que ocorreu na √âpoca 3.
* **M√©tricas:** As mesmas m√©tricas foram calculadas no conjunto de teste de 800 amostras.

---

## üöÄ Instru√ß√µes de Uso

### Pr√©-requisitos
* Python 3.10+
* Uma GPU NVIDIA com CUDA (essencial para performance). O projeto foi testado com CUDA 12.9.
* Git

### 1. Clonar o Reposit√≥rio
```bash
git clone [https://github.com/rafael-rosa/mack-modelos-linguagem-generativos.git](https://github.com/rafael-rosa/mack-modelos-linguagem-generativos.git)
cd mack-modelos-linguagem-generativos
```

### 2. Configurar o Ambiente Virtual

```bash
python -m venv .venv

# No Windows
.venv\Scripts\activate

# No Linux/macOS
source .venv/bin/activate
```

### 3. Instalar as Depend√™ncias

O projeto usa dois arquivos de requisitos. O other-requirements.txt for√ßa a instala√ß√£o do PyTorch com o suporte a CUDA correto.

```bash
pip install --upgrade pip
pip install -r requirements.txt
pip install -r other-requirements.txt
```

### 4. Executar o Notebook

Abra o notebook `movie_review_classif.ipynb` em seu editor de c√≥digo preferido (como VS Code ou Jupyter Lab) e execute as c√©lulas na ordem.

    Nota: Na primeira execu√ß√£o, a biblioteca kagglehub far√° o download do dataset (aprox. 64MB) e os modelos ser√£o baixados (BART-Large tem ~1.6GB e DistilBERT ~268MB). Os checkpoints do modelo treinado ser√£o salvos na pasta ./results.

### ‚ö†Ô∏è IMPORTANTE: Execu√ß√£o via Google Colab

Executar o notebook via Google Colab poder√° exigir o fornecimento de uma API Key do `wandb.ai` no passo **3.2 (Treinamento)**. Obtenha uma API Key criando uma conta em https://wandb.ai/authorize?ref=models e forne√ßa a chave diretamente no Colab no momento em que for solicitada. **O n√£o fornecimento da API Key implicar√° em erro de execu√ß√£o.**



### üìÇ Estrutura do Projeto

<pre>
.
‚îú‚îÄ‚îÄ .venv/                      # Ambiente virtual (ignorado)
‚îú‚îÄ‚îÄ results/                    # Checkpoints do modelo Fine-Tuned (gerado)
‚îú‚îÄ‚îÄ logs/                       # Logs de treino (gerado)
‚îú‚îÄ‚îÄ movie_review_classif.ipynb  # O notebook principal do projeto
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias de Python
‚îú‚îÄ‚îÄ other-requirements.txt      # Depend√™ncias do PyTorch (GPU)
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
</pre>


---

# üí≤Aplica√ß√µes pr√°ticas reais - Plano de neg√≥cios

Duas sugest√µes de aplica√ß√µes poss√≠veis para o projeto, conectando diretamente as tecnologias objetos do teste (***Zero-Shot e Fine-Tuning***) com cen√°rios de neg√≥cio tang√≠veis:

## 1Ô∏è‚É£. Cen√°rio "Cinema & Streaming": ***Term√¥metro de Estreias em Tempo Real***

Este cen√°rio aproveita a for√ßa principal do Zero-Shot: a capacidade de funcionar sem dados pr√©vios.

**O Problema:** Uma plataforma de streaming (como Netflix ou Globoplay) lan√ßa 10 novos t√≠tulos por semana. Eles n√£o t√™m dados hist√≥ricos de reviews para esses filmes espec√≠ficos antes do lan√ßamento. Treinar um modelo novo para cada filme seria invi√°vel e lento.

**A Aplica√ß√£o:** Um sistema de "Monitoramento de Lan√ßamento".

+ O sistema varre o Twitter/X e Reddit nas primeiras 4 horas ap√≥s a estreia.
+ Usa-se o Zero-Shot para classificar o sentimento imediato.

#### üìà **Valor de Neg√≥cio:** 

+ `Marketing Din√¢mico:` Se o sentimento for muito negativo ("O filme √© chato"), a equipe de marketing pode pausar o gasto com an√∫ncios imediatamente para economizar dinheiro.
+ `Gest√£o de Crise:` Se o sentimento for extremamente negativo devido a uma controv√©rsia espec√≠fica, a equipe de PR √© alertada instantaneamente.

## 2Ô∏è‚É£. Cen√°rio "Varejo e Servi√ßos": ***Gest√£o de Reputa√ß√£o***

Este cen√°rio aproveita a for√ßa do modelo Fine-Tuned: efici√™ncia, velocidade e baixo custo computacional para alto volume.

**O Problema:** Grandes redes de franquias (ex: Burger King, Smart Fit, etc) recebem milhares de coment√°rios por dia via Google Maps, Reclame Aqui, App Store e outros canais. Ler tudo manualmente √© imposs√≠vel e rodar um modelo grande para milhares de textos diariamente seria muito caro (custo de GPU/Cloud).

**A Aplica√ß√£o:** Um sistema de "Triagem Autom√°tica de Feedback".

+ Usamos o seu modelo Fine-Tuned, que √© leve e r√°pido.
+ O modelo processa todos os coment√°rios recebidos em batch (ou em tempo real).

#### üìà **Valor de Neg√≥cio:** 

+ `Prioriza√ß√£o de SAC:` Coment√°rios classificados como "Negativos" com alta confian√ßa s√£o enviados para uma fila priorit√°ria de atendimento humano (reten√ß√£o de cliente).
+ `Analytics de Loja:` O sistema gera um dashboard mostrando: "A loja do Shopping X teve 80% de sentimento negativo hoje", permitindo que o gerente regional investigue problemas operacionais (ex: ar condicionado quebrado, atendimento ruim) antes que virem uma crise maior.
